{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute Motion Saliency\n",
    "\n",
    "Here we take a video and iterate through each frame to get the motion saliency\n",
    "The computation is based on OpenCV fonction based on Wang and Dudekâ€™s 2014 publication\n",
    "For each frame, we get an array [width x heigh] were each value represent 0=Non-salient & 1=salient\n",
    "It is mostly based on detection of the background vs object\n",
    "\n",
    "It is possible to display the video saliency at the same time as the computing. \n",
    "\n",
    "This function return an array of (nframe x width x heigh).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import progressbar\n",
    "\n",
    "def ComputeMotionSaliency(path, path_save, file , frameID=None, show=False):\n",
    "    \n",
    "    # import the video and settings\n",
    "    video = cv2.VideoCapture(path+file)\n",
    "    saliency = None\n",
    "    results = None\n",
    "    frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    bar = progressbar.ProgressBar(max_value=frames);\n",
    "    i=1\n",
    "    \n",
    "    \n",
    "    # Iterate trough frames and get motion saliency per frame    \n",
    "    while (video.isOpened()): \n",
    "        # Read frame\n",
    "        ret, frame = video.read() \n",
    "\n",
    "        # If there is no frame (end of video), then stop\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Set up if first frame\n",
    "        if saliency is None:\n",
    "            saliency = cv2.saliency.MotionSaliencyBinWangApr2014_create() # Motion Saliency\n",
    "            saliency.setImagesize(frame.shape[1], frame.shape[0])\n",
    "            saliency.init()\n",
    "\n",
    "        # Use Wang method for motion saliency\n",
    "        grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Convert to grey scale\n",
    "        (success, saliencyMap) = saliency.computeSaliency(grayFrame) # compute saliency\n",
    "\n",
    "        if results is None:\n",
    "            results = np.atleast_3d(saliencyMap)\n",
    "        else:\n",
    "            results = np.append(results, np.atleast_3d(saliencyMap), axis=2)\n",
    "\n",
    "        \n",
    "        if i == frameID:\n",
    "            saliencyMapColored = (saliencyMap * 255).astype(\"uint8\")\n",
    "            cv2.imwrite(path_save+\"{}_frame{}_motionSalience.jpg\".format(file[:-4], frameID), saliencyMapColored)\n",
    "            print('saved')\n",
    "            \n",
    "        \n",
    "        if show:\n",
    "            saliencyMapColored = (saliencyMap * 255).astype(\"uint8\") # Transform to color values\n",
    "            cv2.imshow(\"Map\", saliencyMapColored) # Display the frame\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        # Update Bar\n",
    "        bar.update(i)\n",
    "        i+=1\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    return results.swapaxes(0,2).swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "result = ComputeMotionSaliency(path, path_save, file , frameID=100, show=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "# Static Saliency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVideoValues(path):\n",
    "    \n",
    "    video = cv2.VideoCapture(path)\n",
    "    \n",
    "    if video.isOpened(): \n",
    "        \n",
    "        width  = video.get(cv2.CAP_PROP_FRAME_WIDTH)   # float\n",
    "        height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "    return video, frames, (width, height), fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import progressbar\n",
    "\n",
    "\"\"\"\n",
    "Compute Static Saliency\n",
    "\n",
    "Here we take a video and iterate through each frame to get the static saliency of each frame\n",
    "The computation is based on OpenCV fonction based on Hou and Zhang in their 2007 CVPR paper\n",
    "For each frame, we get an array [width x heigh] were each value represent 0=Non-salient & 1=salient\n",
    "\n",
    "This function return an array of (nframe x width x heigh).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def ComputeStaticSaliency(path, file, method=None, show=False):\n",
    "    \n",
    "    # import the video and settings\n",
    "    video, frames, size, fps = getVideoValues(path+file)\n",
    "    \n",
    "    results = None\n",
    "    bar = progressbar.ProgressBar(max_value=frames);\n",
    "    i=1\n",
    "    \n",
    "    # Set saliency algorithm to use\n",
    "    if method is 'spectral':  \n",
    "#         print('Using Spectral Residual Method')\n",
    "        saliency =  cv2.saliency.StaticSaliencySpectralResidual_create() # Use Spectral Residual method\n",
    "    else: \n",
    "#         print('Using Fine Grained Method')\n",
    "        saliency = cv2.saliency.StaticSaliencyFineGrained_create() # Use Fine Grained method \n",
    "\n",
    "    \n",
    "    # Iterate trough frames and get saliency per frame    \n",
    "    while (video.isOpened()): \n",
    "        # Read frame\n",
    "        ret, frame = video.read() \n",
    "\n",
    "        # If there is no frame (end of video), then stop\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply chosen method on frame\n",
    "        (success, saliencyMap) = saliency.computeSaliency(frame)\n",
    "        \n",
    "        # Save result in np array\n",
    "        if results is None:\n",
    "            results = np.atleast_3d(saliencyMap)\n",
    "        else:\n",
    "            results = np.append(results, np.atleast_3d(saliencyMap), axis=2)\n",
    "            \n",
    "            \n",
    "        # colored and save new frame in video\n",
    "        saliencyMapColored = (saliencyMap * 255).astype(\"uint8\") # change [0 to 1] to [1 to 255] to display\n",
    "        \n",
    "        # Display result\n",
    "        if show:\n",
    "            cv2.imshow(\"{} Map\".format(method), saliencyMapColored) # Show frame / update new frame\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "        # Update Bar\n",
    "        bar.update(i)\n",
    "        i+=1\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    return results.swapaxes(0,2).swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/ramme/Dev/Manip-Maitrise/Z_BanqueVideo/\"\n",
    "path_save = \"C:/Users/ramme/Dev/Analyse-Maitrise/Videos/result/OpenCV/\"\n",
    "files = ['1Neutral_escalade.mp4', '1Neutral_kid_writing.mp4', '2vid18.mp4', '2vid44.mp4', '3vid9.mp4', '3vid120.mp4']\n",
    "frames = [300, 300, 175, 175, 175, 350]\n",
    "i=0\n",
    "\n",
    "for file, frame in zip(files, frames):\n",
    "    result = ComputeStaticSaliency(path, file, method='FineGrained', show=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "# Motion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import progressbar\n",
    "\n",
    "def ComputeMotionDetection(path, path_save, file, frameID=None, treshold_value=20, show=False):\n",
    "    \n",
    "    # import the video and settings\n",
    "    video, frames, size, fps = getVideoValues(path+file)\n",
    "    results = None\n",
    "    bar = progressbar.ProgressBar(max_value=frames);\n",
    "    i=1\n",
    "    \n",
    "    ret, frame1 = video.read()\n",
    "    ret, frame2 = video.read()\n",
    "    \n",
    "    # Iterate trough frames and get saliency per frame    \n",
    "    while (video.isOpened()): \n",
    "                    \n",
    "        # Difference between Frame 1 and Frame 2\n",
    "        diff = cv2.absdiff(frame1, frame2)\n",
    "        \n",
    "        # Convert to gray Scale\n",
    "        gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        \n",
    "        _, thresh = cv2.threshold(blur, treshold_value, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        if show:\n",
    "            cv2.imshow('Difference Frame', thresh)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        # save frame in JPG\n",
    "        if i==frameID:\n",
    "            cv2.imwrite(path_save+\"{}_frame{}_MotionDetection{}.jpg\".format(file[:-4], frameID, treshold_value), thresh)\n",
    "        \n",
    "        # Save result in np array\n",
    "        if results is None:\n",
    "            results = np.atleast_3d(thresh)\n",
    "        else:\n",
    "            results = np.append(results, np.atleast_3d(thresh), axis=2)\n",
    "            \n",
    "        \n",
    "        # Assign frame2(image) to frame1(image)\n",
    "        frame1 = frame2\n",
    "\n",
    "        #Read new frame2\n",
    "        ret, frame2 = video.read()\n",
    "        \n",
    "        # Update Bar\n",
    "        bar.update(i)\n",
    "        i+=1\n",
    "                \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    return results.swapaxes(0,2).swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/ramme/Dev/Manip-Maitrise/Z_BanqueVideo/\"\n",
    "path_save = \"C:/Users/ramme/Dev/Analyse-Maitrise/Videos/result/OpenCV/\"\n",
    "files = ['1Neutral_escalade.mp4', '1Neutral_kid_writing.mp4', '2vid18.mp4', '2vid44.mp4', '3vid9.mp4', '3vid120.mp4']\n",
    "frames = [300, 300, 175, 175, 175, 350]\n",
    "i=0\n",
    "\n",
    "for file, frame in zip(files, frames):\n",
    "    result = ComputeMotionDetection(path, path_save, file , frame, 50 ,show=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Specific Frame (Static Salience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import progressbar\n",
    "\n",
    "def ComputeSpecificFrame(path, path_save, file , frameID=100, show=False):\n",
    "      \n",
    "    # import the video and settings\n",
    "    video = cv2.VideoCapture(path+file)\n",
    "    frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    if frameID > frames:\n",
    "        print('Frame do not exist, please select a frame under {}'.format(frames))\n",
    "    \n",
    "    i=1\n",
    "    \n",
    "    # Iterate trough frames and get saliency per frame    \n",
    "    while (video.isOpened()): \n",
    "        ret, frame = video.read() \n",
    "\n",
    "        # If there is no frame (end of video), then stop\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        elif i == frameID:\n",
    "            \n",
    "            # Save Original Frame\n",
    "            cv2.imwrite(path_save+\"{}_frame{}_original.jpg\".format(file[:-4], frameID), frame)\n",
    "            \n",
    "            # Compute SpectralResidualfor static Saliency\n",
    "            saliency_SR =  cv2.saliency.StaticSaliencySpectralResidual_create()\n",
    "            (success, saliencyMap_SR) = saliency_SR.computeSaliency(frame)\n",
    "            saliencyMap_SR = (saliencyMap_SR * 255).astype(\"uint8\")\n",
    "            cv2.imwrite(path_save+\"{}_frame{}_SpectralResidual.jpg\".format(file[:-4], frameID), saliencyMap_SR)\n",
    "\n",
    "            # Compute Fine Grained \n",
    "            saliency_FG = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "            (success, saliencyMap_FG) = saliency_FG.computeSaliency(frame)\n",
    "            saliencyMap_FG = (saliencyMap_FG * 255).astype(\"uint8\")\n",
    "            cv2.imwrite(path_save+\"{}_frame{}_FineGrained.jpg\".format(file[:-4], frameID), saliencyMap_FG)\n",
    "            \n",
    "\n",
    "            \n",
    "            if show:\n",
    "                cv2.imshow(\"Real Image\", frame)\n",
    "                cv2.imshow(\"Spectral Residual\", saliencyMap_SR)\n",
    "                cv2.imshow(\"Fine Grained Map\", saliencyMap_FG)\n",
    "                \n",
    "                cv2.waitKey()\n",
    "                cv2.destroyAllWindows()\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/ramme/Dev/Manip-Maitrise/Z_BanqueVideo/\"\n",
    "path_save = \"C:/Users/ramme/Dev/Analyse-Maitrise/Videos/result/OpenCV/\"\n",
    "files = ['1Neutral_escalade .mp4', '1Neutral_kid_writing.mp4', '2vid18.mp4', '2vid44.mp4', '3vid9.mp4', '3vid120.mp4']\n",
    "frames = [300, 300, 175, 175, 175, 350]\n",
    "i=0\n",
    "\n",
    "for file, frame in zip(files, frames):\n",
    "    result = ComputeSpecificFrame(path, path_save, file, frame, show=True);\n",
    "    result = ComputeMotionSaliency(path, path_save, file , frame, show=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Setup\n",
    "path = \"C:/Users/ramme/Dev/Manip-Maitrise/Z_BanqueVideo/\"\n",
    "path_save = \"C:/Users/ramme/Dev/Analyse-Maitrise/Videos/result/OpenCV_NPZ/\"\n",
    "\n",
    "\n",
    "\n",
    "# Select file to use\n",
    "# files = ['1Neutral_escalade.mp4', '2vid44.mp4'] # test file\n",
    "files = os.listdir(path) # all data\n",
    "\n",
    "\n",
    "# Bar update\n",
    "for file in files:\n",
    "    print('Computing:', file)\n",
    "    \n",
    "    data_method= []\n",
    "    data_array = []\n",
    "    \n",
    "    # Compute Fine Grained Motion\n",
    "    data_method.append('FineGrained')\n",
    "    data_array.append(ComputeStaticSaliency(path, file, 'FineGrained'))\n",
    "    \n",
    "    # Compute Motion Detection\n",
    "    data_method.append('MotionDetection')\n",
    "    data_array.append(ComputeMotionDetection(path, path_save, file))\n",
    "    \n",
    "    # Compute Motion Saliency\n",
    "    data_method.append('MotionSaliency')\n",
    "    data_array.append(ComputeMotionSaliency(path, path_save, file))\n",
    "       \n",
    "    \n",
    "    np.savez(path_save+'{}_computeNPZ.npz'.format(file), data_method=data_method, data_array=data_array)  # data is a dict here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(path_save+'1EDIT_neutre_train_a.mp4_computeNPZ.npz', allow_pickle=True)\n",
    "data.files\n",
    "d=data['data_method']\n",
    "print(d[0].shape)\n",
    "print(d[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Video In Time & Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computation_T5X3Y3_mean\n",
      "3Funny paddleboat GA.mp4_computeNPZ.npz ERROR: not working for some reason\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function NpzFile.__del__ at 0x000001FEFEAF8840>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ramme\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\", line 230, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\ramme\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\", line 221, in close\n",
      "    if self.zip is not None:\n",
      "AttributeError: 'NpzFile' object has no attribute 'zip'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# files = ['1EDIT_neutre_train_a.mp4_computeNPZ.npz', '1Neutral_baseball_GA.mp4_computeNPZ.npz'] # test file\n",
    "files = os.listdir('./result/OpenCV_NPZ/') # all data\n",
    "\n",
    "def mean_time_space(time_clusters=1, space_clusters_x=1, space_clusters_y=1):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Bar update\n",
    "    for file in files:\n",
    "        # Load Completed File  \n",
    "        try:\n",
    "            data = np.load('./result/OpenCV_NPZ/'+file, allow_pickle=True)\n",
    "        except:\n",
    "            print(file, 'ERROR: not working for some reason')\n",
    "            continue\n",
    "\n",
    "        for selected_method in [0,1]:\n",
    "            d=data['data_array'][selected_method]\n",
    "            \n",
    "            row = pd.DataFrame.from_dict({\n",
    "                    'method':[data['data_method'][selected_method]],\n",
    "                    'video':[file[:-15]]})\n",
    "\n",
    "            time_bins      = int(d.shape[0]/time_clusters)\n",
    "            space_bins_y   = int(d.shape[1]/space_clusters_x)\n",
    "            space_bins_x   = int(d.shape[2]/space_clusters_y)\n",
    "\n",
    "            # Split in time / space:\n",
    "            for time in range(time_clusters):\n",
    "                for space_x in range(space_clusters_x):\n",
    "                    for space_y in range(space_clusters_y):\n",
    "                        row['T'+str(time)+'X'+str(space_x)+'Y'+str(space_y)]= d[time*time_bins:(time+1)*time_bins,space_y*space_bins_y:(space_y+1)*space_bins_y, space_x*space_bins_x:(space_x+1)*space_bins_x].mean() \n",
    "            df = pd.concat([df, row])\n",
    "                    \n",
    "    return df\n",
    "\n",
    "\n",
    "print('computation_T5X3Y3_mean')\n",
    "mean_time_space(5,3,3).to_csv('./result/OpenCV_NPZ_Compute/computation_T5X3Y3_mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computation_T5X3Y3_STD\n",
      "3Funny paddleboat GA.mp4_computeNPZ.npz ERROR: not working for some reason\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function NpzFile.__del__ at 0x000001FEFEAF8840>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ramme\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\", line 230, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\ramme\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\", line 221, in close\n",
      "    if self.zip is not None:\n",
      "AttributeError: 'NpzFile' object has no attribute 'zip'\n"
     ]
    }
   ],
   "source": [
    "def mean_time_space(time_clusters=1, space_clusters_x=1, space_clusters_y=1):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Bar update\n",
    "    for file in files:\n",
    "        # Load Completed File  \n",
    "        try:\n",
    "            data = np.load('./result/OpenCV_NPZ/'+file, allow_pickle=True)\n",
    "        except:\n",
    "            print(file, 'ERROR: not working for some reason')\n",
    "            continue\n",
    "\n",
    "        for selected_method in [0,1]:\n",
    "            d=data['data_array'][selected_method]\n",
    "            \n",
    "            row = pd.DataFrame.from_dict({\n",
    "                    'method':[data['data_method'][selected_method]],\n",
    "                    'video':[file[:-15]]})\n",
    "\n",
    "            time_bins      = int(d.shape[0]/time_clusters)\n",
    "            space_bins_y   = int(d.shape[1]/space_clusters_x)\n",
    "            space_bins_x   = int(d.shape[2]/space_clusters_y)\n",
    "\n",
    "            # Split in time / space:\n",
    "            for time in range(time_clusters):\n",
    "                for space_x in range(space_clusters_x):\n",
    "                    for space_y in range(space_clusters_y):\n",
    "                        row['T'+str(time)+'X'+str(space_x)+'Y'+str(space_y)]= d[time*time_bins:(time+1)*time_bins,space_y*space_bins_y:(space_y+1)*space_bins_y, space_x*space_bins_x:(space_x+1)*space_bins_x].std() \n",
    "            df = pd.concat([df, row])\n",
    "                    \n",
    "    return df\n",
    "\n",
    "\n",
    "print('computation_T5X3Y3_STD')\n",
    "mean_time_space(5,3,3).to_csv('./result/OpenCV_NPZ_Compute/computation_T5X3Y3_STD.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
